{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnLNO/HhTlctG7CYnfte7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52241-svg/NLP/blob/main/Lab8_2_K_Akhil_2403a52241.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**corpus**"
      ],
      "metadata": {
        "id": "fCEYq23hPqbR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl0GkogJPa5b"
      },
      "outputs": [],
      "source": [
        "D1: \"I am studying B.Tech in Computer Science at SR University.\"\n",
        "\n",
        "D2:\" I am learning programming, data structures, and machine learning during my B.Tech course.\"\n",
        "\n",
        "D3: \"I completed my intermediate education in MPC with strong interest in mathematics.\"\n",
        "\n",
        "D4: \"I want to become a software engineer and build innovative technology solutions.\"\n",
        "\n",
        "D5:\"I am actively working on improving my coding skills by practicing problems on platforms like LeetCode, HackerRank, and Codeforces.\"\n",
        "\n",
        "D6:\"I am building small projects in web development and machine learning to apply my theoretical knowledge into practical solutions.\"\n",
        "\n",
        "D7: \"I am focusing on mastering data structures and algorithms to prepare for technical interviews and competitive programming.\"\n",
        "\n",
        "D8:\"I am exploring internships and industry projects to gain real-world experience and understand software development practices.\"\n",
        "\n",
        "D9: \"I am enhancing my communication and teamwork skills by participating in group projects, hackathons, and technical events.\"\n",
        "\n",
        "D10:\"My long-term vision is to contribute to cutting-edge technologies, innovate solutions that solve real-world problems, and grow as a professional software engineer.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**uni gram counts**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "46GD1KE2P3p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "D1: \"I am studying B.Tech in Computer Science at SR University.\"\n",
        "\n",
        "D2:\" I am learning programming, data structures, and machine learning during my B.Tech course.\"\n",
        "\n",
        "D3: \"I completed my intermediate education in MPC with strong interest in mathematics.\"\n",
        "\n",
        "D4: \"I want to become a software engineer and build innovative technology solutions.\"\n",
        "\n",
        "D5:\"I am actively working on improving my coding skills by practicing problems on platforms like LeetCode, HackerRank, and Codeforces.\"\n",
        "\n",
        "D6:\"I am building small projects in web development and machine learning to apply my theoretical knowledge into practical solutions.\"\n",
        "\n",
        "D7: \"I am focusing on mastering data structures and algorithms to prepare for technical interviews and competitive programming.\"\n",
        "\n",
        "D8:\"I am exploring internships and industry projects to gain real-world experience and understand software development practices.\"\n",
        "\n",
        "D9: \"I am enhancing my communication and teamwork skills by participating in group projects, hackathons, and technical events.\"\n",
        "\n",
        "D10:\"My long-term vision is to contribute to cutting-edge technologies, innovate solutions that solve real-world problems, and grow as a professional software engineer.\"\n",
        "\n",
        "D1_content = \"I am studying B.Tech in Computer Science at SR University.\"\n",
        "D2_content = \"I am learning programming, data structures, and machine learning during my B.Tech course.\"\n",
        "D3_content = \"I completed my intermediate education in MPC with strong interest in mathematics.\"\n",
        "D4_content = \"I want to become a software engineer and build innovative technology solutions.\"\n",
        "D6_content =\"I am building small projects in web development and machine learning to apply my theoretical knowledge into practical solutions.\"\n",
        "D7_content =\"I am focusing on mastering data structures and algorithms to prepare for technical interviews and competitive programming.\"\n",
        "D5_content =\"I am actively working on improving my coding skills by practicing problems on platforms like LeetCode, HackerRank, and Codeforces.\"\n",
        "D8_content =\"I am exploring internships and industry projects to gain real-world experience and understand software development practices.\"\n",
        "D9_content =\"I am enhancing my communication and teamwork skills by participating in group projects, hackathons, and technical events.\"\n",
        "D10_content =\"My long-term vision is to contribute to cutting-edge technologies, innovate solutions that solve real-world problems, and grow as a professional software engineer.\"\n",
        "\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content}\"\n",
        "\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyxg0anKP5tq",
        "outputId": "3af80a84-ae2c-43cc-c7b4-e6e205622c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "i: 4\n",
            "in: 3\n",
            "am: 2\n",
            "b.tech: 2\n",
            "learning: 2\n",
            "and: 2\n",
            "my: 2\n",
            "studying: 1\n",
            "computer: 1\n",
            "science: 1\n",
            "at: 1\n",
            "sr: 1\n",
            "university.: 1\n",
            "programming,: 1\n",
            "data: 1\n",
            "structures,: 1\n",
            "machine: 1\n",
            "during: 1\n",
            "course.: 1\n",
            "completed: 1\n",
            "intermediate: 1\n",
            "education: 1\n",
            "mpc: 1\n",
            "with: 1\n",
            "strong: 1\n",
            "interest: 1\n",
            "mathematics.: 1\n",
            "want: 1\n",
            "to: 1\n",
            "become: 1\n",
            "a: 1\n",
            "software: 1\n",
            "engineer: 1\n",
            "build: 1\n",
            "innovative: 1\n",
            "technology: 1\n",
            "solutions.: 1\n",
            "Vocabulary Size= 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bi-gram count**"
      ],
      "metadata": {
        "id": "S6lynSkBQCm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u-dlANOQFcS",
        "outputId": "ef47b63d-9a8a-47b6-f3a1-9e1624d62e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "i am: 2\n",
            "am studying: 1\n",
            "studying b.tech: 1\n",
            "b.tech in: 1\n",
            "in computer: 1\n",
            "computer science: 1\n",
            "science at: 1\n",
            "at sr: 1\n",
            "sr university.: 1\n",
            "university. i: 1\n",
            "am learning: 1\n",
            "learning programming,: 1\n",
            "programming, data: 1\n",
            "data structures,: 1\n",
            "structures, and: 1\n",
            "and machine: 1\n",
            "machine learning: 1\n",
            "learning during: 1\n",
            "during my: 1\n",
            "my b.tech: 1\n",
            "b.tech course.: 1\n",
            "course. i: 1\n",
            "i completed: 1\n",
            "completed my: 1\n",
            "my intermediate: 1\n",
            "intermediate education: 1\n",
            "education in: 1\n",
            "in mpc: 1\n",
            "mpc with: 1\n",
            "with strong: 1\n",
            "strong interest: 1\n",
            "interest in: 1\n",
            "in mathematics.: 1\n",
            "mathematics. i: 1\n",
            "i want: 1\n",
            "want to: 1\n",
            "to become: 1\n",
            "become a: 1\n",
            "a software: 1\n",
            "software engineer: 1\n",
            "engineer and: 1\n",
            "and build: 1\n",
            "build innovative: 1\n",
            "innovative technology: 1\n",
            "technology solutions.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tri-gram counts**"
      ],
      "metadata": {
        "id": "AxnXeIFSQMX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKzu3OR_QQSe",
        "outputId": "c5e6622f-9a96-4da5-bfb7-15387a6c7486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "i am studying: 1\n",
            "am studying b.tech: 1\n",
            "studying b.tech in: 1\n",
            "b.tech in computer: 1\n",
            "in computer science: 1\n",
            "computer science at: 1\n",
            "science at sr: 1\n",
            "at sr university.: 1\n",
            "sr university. i: 1\n",
            "university. i am: 1\n",
            "i am learning: 1\n",
            "am learning programming,: 1\n",
            "learning programming, data: 1\n",
            "programming, data structures,: 1\n",
            "data structures, and: 1\n",
            "structures, and machine: 1\n",
            "and machine learning: 1\n",
            "machine learning during: 1\n",
            "learning during my: 1\n",
            "during my b.tech: 1\n",
            "my b.tech course.: 1\n",
            "b.tech course. i: 1\n",
            "course. i completed: 1\n",
            "i completed my: 1\n",
            "completed my intermediate: 1\n",
            "my intermediate education: 1\n",
            "intermediate education in: 1\n",
            "education in mpc: 1\n",
            "in mpc with: 1\n",
            "mpc with strong: 1\n",
            "with strong interest: 1\n",
            "strong interest in: 1\n",
            "interest in mathematics.: 1\n",
            "in mathematics. i: 1\n",
            "mathematics. i want: 1\n",
            "i want to: 1\n",
            "want to become: 1\n",
            "to become a: 1\n",
            "become a software: 1\n",
            "a software engineer: 1\n",
            "software engineer and: 1\n",
            "engineer and build: 1\n",
            "and build innovative: 1\n",
            "build innovative technology: 1\n",
            "innovative technology solutions.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next wourld prediction using Bi-gram counts**"
      ],
      "metadata": {
        "id": "Z_tXBCF6Qc9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP76IrEKQipX",
        "outputId": "c9a475c2-5d10-4e2d-b1bf-9b1fccb92d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  studying is  0.5\n",
            "probability of  learning is  0.5\n",
            "Given sequence: 'I am', predicted next word: 'studying'\n",
            "probability of  b.tech is  0.5\n",
            "probability of  intermediate is  0.5\n",
            "Given sequence: 'I did my', predicted next word: 'b.tech'\n",
            "probability of  am is  0.5\n",
            "probability of  completed is  0.25\n",
            "probability of  want is  0.25\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Diployment of bi-gram model**"
      ],
      "metadata": {
        "id": "ws8wvuA5Qq7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEmJgFs9Qqm-",
        "outputId": "11352dbc-5163-4e8b-8fc6-7eb2e037c1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textwant\n",
            "probability of  to is  1.0\n",
            "Given sequence: 'want', predicted next word: 'to'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next world prediction using tr-gram counts**"
      ],
      "metadata": {
        "id": "FYdeA4rvQ7VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "    # Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uju1fq9IQ8C9",
        "outputId": "b1f95f1f-0e78-49e3-d3ac-3900df15aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "tcZdLVAtRMZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkDBsZEARMKj",
        "outputId": "602efee1-946c-4fa3-931c-ff3626cace7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textstudying\n",
            "Given sequence: 'studying', predicted next word: 'Sequence must contain at least two words for trigram prediction.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "donMVatfRZbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMAduEDfRZ_f",
        "outputId": "1de8f05b-a696-48cb-f89e-7e2bdee2c962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of studying is  0.05128205128205128\n",
            "probability of learning is  0.05128205128205128\n",
            "Given sequence: 'I am', predicted next word: 'studying'\n",
            "probability of b.tech is  0.05128205128205128\n",
            "probability of intermediate is  0.05128205128205128\n",
            "Given sequence: 'I did my', predicted next word: 'b.tech'\n",
            "probability of am is  0.07317073170731707\n",
            "probability of completed is  0.04878048780487805\n",
            "probability of want is  0.04878048780487805\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "mPHYCjggRrgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA49Nl4MRrOq",
        "outputId": "6385fa77-8178-4c79-a1bb-696cfaad7f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of studying is  0.05128205128205128\n",
            "probability of learning is  0.05128205128205128\n",
            "Given sequence: 'i am', predicted next word: 'studying'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "5mDnglrUR1rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqZV2IiVR1WP",
        "outputId": "e3f8babe-5992-43ca-9028-0c306dff9436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "0igJ9MXqSMeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKtEQX1QSMJ_",
        "outputId": "2dd1331c-1ade-4a8c-f91b-efa797f19256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textto be\n",
            "Given sequence: 'to be', predicted next word: 'No trigram found starting with 'to be'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next Word Prediction Using Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "TZFyYA9pSXpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G8zX70HSY_J",
        "outputId": "bbd2e725-44fa-4727-b0ae-12ac0c96f81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of studying is  0.07317073170731707\n",
            "probability of learning is  0.07317073170731707\n",
            "Given sequence: 'I am', predicted next word: 'studying'\n",
            "probability of b.tech is  0.07317073170731707\n",
            "probability of intermediate is  0.07317073170731707\n",
            "Given sequence: 'I did my', predicted next word: 'b.tech'\n",
            "probability of am is  0.1111111111111111\n",
            "probability of completed is  0.06666666666666667\n",
            "probability of want is  0.06666666666666667\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVB2Hnx3a7si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "EMY08zkXSzeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zinMi_6mS0Qm",
        "outputId": "65197781-1773-4dd5-997c-cab1691f8120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of  studying is  0.07317073170731707\n",
            "probability of  learning is  0.07317073170731707\n",
            "Given sequence: 'i am', predicted next word: 'studying'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444bf517"
      },
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts, K):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    # Calculate the count of the bigram (w1, w2) for the denominator in Add-K smoothing\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "\n",
        "    if not potential_next_words and last_two_words_bigram_count == 0:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}' and bigram prefix also not found.\"\n",
        "    elif not potential_next_words:\n",
        "        # If potential_next_words is empty but last_two_words_bigram_count > 0, it means the prefix exists\n",
        "        # but never led to a recorded trigram. For Add-K, all V words would have P = K / (last_two_words_bigram_count + K*V).\n",
        "        # However, to maintain consistency with other predict_next_word functions, we'll return 'No trigram found...'\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    # Apply Add-K smoothing: P(w3 | w1,w2) = (Count(w1, w2, w3) + K) / (Count(w1, w2) + K*V)\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        # V is the global vocabulary size, defined in cell qyxg0anKP5tq\n",
        "        probability = (trigram_count + K) / (last_two_words_bigram_count + K * V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage (optional, can be removed if not needed for direct testing):\n",
        "# sequence1_k = \"I am studying\"\n",
        "# next_word1_k = predict_next_word_trigram_K(sequence1_k, Trigrams_counts, bigram_counts, 0.5)\n",
        "# print(f\"Given sequence: '{sequence1_k}', predicted next word: '{next_word1_k}'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3922e6a8",
        "outputId": "d5ea4fd5-b7eb-40d6-ad20-36dd30c06bf1"
      },
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of  studying is  0.07317073170731707\n",
            "probability of  learning is  0.07317073170731707\n",
            "Given sequence: 'i am', predicted next word: 'studying'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Thank You**"
      ],
      "metadata": {
        "id": "hblOItt0Y0jY"
      }
    }
  ]
}